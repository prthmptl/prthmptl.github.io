<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>My New Hugo Site</title><link>https://prthmptl.github.io/</link><description>Recent content on My New Hugo Site</description><generator>Hugo -- 0.143.1</generator><language>en-us</language><lastBuildDate>Sat, 15 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://prthmptl.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Understanding CUDA: A Simple Vector Addition Example</title><link>https://prthmptl.github.io/blog/vecaddkernel/</link><pubDate>Sat, 15 Feb 2025 00:00:00 +0000</pubDate><guid>https://prthmptl.github.io/blog/vecaddkernel/</guid><description>&lt;h1 id="understanding-cuda-a-simple-vector-addition-example">Understanding CUDA: A Simple Vector Addition Example&lt;/h1>
&lt;p>CUDA (Compute Unified Device Architecture) is a parallel computing platform by NVIDIA that allows developers to leverage the massive computational power of GPUs. In this blog, we&amp;rsquo;ll break down a simple CUDA program that performs vector addition using GPU acceleration.&lt;/p>
&lt;h2 id="the-code">The Code&lt;/h2>
&lt;p>Let&amp;rsquo;s analyze the given CUDA program, which adds two vectors element-wise using parallel processing:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#include&lt;/span> &lt;span style="color:#75715e">&amp;lt;iostream&amp;gt;&lt;/span>&lt;span style="color:#75715e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#include&lt;/span> &lt;span style="color:#75715e">&amp;lt;cuda_runtime.h&amp;gt;&lt;/span>&lt;span style="color:#75715e">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>__global__
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#a6e22e">vecAddKernel&lt;/span>(&lt;span style="color:#66d9ef">float&lt;/span>&lt;span style="color:#f92672">*&lt;/span> A, &lt;span style="color:#66d9ef">float&lt;/span>&lt;span style="color:#f92672">*&lt;/span> B, &lt;span style="color:#66d9ef">float&lt;/span>&lt;span style="color:#f92672">*&lt;/span> C, &lt;span style="color:#66d9ef">int&lt;/span> n) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> i &lt;span style="color:#f92672">=&lt;/span> threadIdx.x &lt;span style="color:#f92672">+&lt;/span> blockDim.x &lt;span style="color:#f92672">*&lt;/span> blockIdx.x;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (i &lt;span style="color:#f92672">&amp;lt;&lt;/span> n) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> C[i] &lt;span style="color:#f92672">=&lt;/span> A[i] &lt;span style="color:#f92672">+&lt;/span> B[i];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">int&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>() {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> n &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">256&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">float&lt;/span> A[n], B[n], C[n];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span>(&lt;span style="color:#66d9ef">int&lt;/span> i&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>; i&lt;span style="color:#f92672">&amp;lt;=&lt;/span>n; i&lt;span style="color:#f92672">++&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> A[i&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> i;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> B[i&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> i;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">float&lt;/span> &lt;span style="color:#f92672">*&lt;/span>A_d, &lt;span style="color:#f92672">*&lt;/span>B_d, &lt;span style="color:#f92672">*&lt;/span>C_d;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> size &lt;span style="color:#f92672">=&lt;/span> n &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#66d9ef">sizeof&lt;/span>(&lt;span style="color:#66d9ef">float&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cudaMalloc((&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">**&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span>A_d, size);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cudaMalloc((&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">**&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span>B_d, size);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cudaMalloc((&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">**&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span>C_d, size);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cudaMemcpy(A_d, A, size, cudaMemcpyHostToDevice);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cudaMemcpy(B_d, B, size, cudaMemcpyHostToDevice);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> vecAddKernel&lt;span style="color:#f92672">&amp;lt;&amp;lt;&amp;lt;&lt;/span>ceil(n&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">256.0&lt;/span>), &lt;span style="color:#ae81ff">256&lt;/span>&lt;span style="color:#f92672">&amp;gt;&amp;gt;&amp;gt;&lt;/span>(A_d, B_d, C_d, n);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cudaMemcpy(C, C_d, size, cudaMemcpyDeviceToHost);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span>(&lt;span style="color:#66d9ef">int&lt;/span> i&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>; i&lt;span style="color:#f92672">&amp;lt;&lt;/span>n; i&lt;span style="color:#f92672">++&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> printf(&lt;span style="color:#e6db74">&amp;#34;%.2f&lt;/span>&lt;span style="color:#ae81ff">\n&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>, C[i]);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cudaFree(A_d);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cudaFree(B_d);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cudaFree(C_d);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="breaking-it-down">Breaking It Down&lt;/h2>
&lt;h3 id="1-the-kernel-function">1. The Kernel Function&lt;/h3>
&lt;p>The function &lt;code>vecAddKernel&lt;/code> is a CUDA kernel, which means it runs on the GPU. It follows this format:&lt;/p></description></item></channel></rss>