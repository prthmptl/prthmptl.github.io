<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Matrix Multiplication with CUDA: A Beginner&#39;s Guide | Pratham Patel</title>
<meta name="keywords" content="">
<meta name="description" content="Matrix Multiplication with CUDA: A Beginner&rsquo;s Guide
Matrix multiplication is a fundamental operation in scientific computing, machine learning, and computer graphics. Leveraging the parallel processing power of GPUs can significantly speed up matrix operations. In this blog, we&rsquo;ll break down a CUDA-based matrix multiplication program step by step, explaining it in an intuitive manner.
Why Use CUDA for Matrix Multiplication?
Matrix multiplication involves many repeated calculations that can be performed in parallel. CPUs process computations sequentially for the most part, whereas GPUs excel at handling thousands of parallel operations. CUDA allows us to write programs that run efficiently on NVIDIA GPUs, leveraging their parallel computing capabilities.">
<meta name="author" content="Pratham Patel">
<link rel="canonical" href="http://localhost:1313/blog/matmulkernel/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/blog/matmulkernel/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Pratham Patel (Alt + H)">Pratham Patel</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/contact/" title="Contact">
                    <span>Contact</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Matrix Multiplication with CUDA: A Beginner&#39;s Guide
    </h1>
    <div class="post-meta"><span title='2025-02-16 00:00:00 +0000 UTC'>February 16, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Pratham Patel

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#matrix-multiplication-with-cuda-a-beginners-guide" aria-label="Matrix Multiplication with CUDA: A Beginner&rsquo;s Guide">Matrix Multiplication with CUDA: A Beginner&rsquo;s Guide</a><ul>
                        
                <li>
                    <a href="#why-use-cuda-for-matrix-multiplication" aria-label="Why Use CUDA for Matrix Multiplication?">Why Use CUDA for Matrix Multiplication?</a></li>
                <li>
                    <a href="#understanding-the-code-step-by-step" aria-label="Understanding the Code Step by Step">Understanding the Code Step by Step</a><ul>
                        
                <li>
                    <a href="#1-including-required-headers" aria-label="1. Including Required Headers">1. Including Required Headers</a></li>
                <li>
                    <a href="#2-cuda-kernel-for-matrix-multiplication" aria-label="2. CUDA Kernel for Matrix Multiplication">2. CUDA Kernel for Matrix Multiplication</a></li>
                <li>
                    <a href="#breaking-down-the-cuda-kernel-with-an-example" aria-label="Breaking Down the CUDA Kernel with an Example">Breaking Down the CUDA Kernel with an Example</a><ul>
                        
                <li>
                    <a href="#example-matrix-multiplication" aria-label="Example Matrix Multiplication">Example Matrix Multiplication</a></li></ul>
                </li>
                <li>
                    <a href="#how-cuda-threads-process-this-computation" aria-label="How CUDA Threads Process This Computation">How CUDA Threads Process This Computation</a></li>
                <li>
                    <a href="#explanation-of-cuda-thread-indexing" aria-label="Explanation of CUDA Thread Indexing">Explanation of CUDA Thread Indexing</a><ul>
                        
                <li>
                    <a href="#understanding-index-computation" aria-label="Understanding Index Computation">Understanding Index Computation</a></li></ul>
                </li>
                <li>
                    <a href="#3-main-function-memory-allocation-and-execution" aria-label="3. Main Function: Memory Allocation and Execution">3. Main Function: Memory Allocation and Execution</a><ul>
                        
                <li>
                    <a href="#initializing-matrices" aria-label="Initializing Matrices">Initializing Matrices</a></li>
                <li>
                    <a href="#copying-data-to-gpu" aria-label="Copying Data to GPU">Copying Data to GPU</a></li></ul>
                </li>
                <li>
                    <a href="#4-launching-the-cuda-kernel" aria-label="4. Launching the CUDA Kernel">4. Launching the CUDA Kernel</a></li>
                <li>
                    <a href="#5-copying-results-back-to-cpu-and-printing" aria-label="5. Copying Results Back to CPU and Printing">5. Copying Results Back to CPU and Printing</a></li>
                <li>
                    <a href="#6-freeing-memory" aria-label="6. Freeing Memory">6. Freeing Memory</a></li></ul>
                </li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="matrix-multiplication-with-cuda-a-beginners-guide">Matrix Multiplication with CUDA: A Beginner&rsquo;s Guide<a hidden class="anchor" aria-hidden="true" href="#matrix-multiplication-with-cuda-a-beginners-guide">#</a></h1>
<p>Matrix multiplication is a fundamental operation in scientific computing, machine learning, and computer graphics. Leveraging the parallel processing power of GPUs can significantly speed up matrix operations. In this blog, we&rsquo;ll break down a CUDA-based matrix multiplication program step by step, explaining it in an intuitive manner.</p>
<h2 id="why-use-cuda-for-matrix-multiplication">Why Use CUDA for Matrix Multiplication?<a hidden class="anchor" aria-hidden="true" href="#why-use-cuda-for-matrix-multiplication">#</a></h2>
<p>Matrix multiplication involves many repeated calculations that can be performed in parallel. CPUs process computations sequentially for the most part, whereas GPUs excel at handling thousands of parallel operations. CUDA allows us to write programs that run efficiently on NVIDIA GPUs, leveraging their parallel computing capabilities.</p>
<h2 id="understanding-the-code-step-by-step">Understanding the Code Step by Step<a hidden class="anchor" aria-hidden="true" href="#understanding-the-code-step-by-step">#</a></h2>
<p>This C++ program with CUDA performs matrix multiplication using GPU acceleration. Let&rsquo;s break it down logically.</p>
<h3 id="1-including-required-headers">1. Including Required Headers<a hidden class="anchor" aria-hidden="true" href="#1-including-required-headers">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;iostream&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;cuda_runtime.h&gt;</span><span style="color:#75715e">
</span></span></span></code></pre></div><p>We include <code>&lt;iostream&gt;</code> for input-output operations and <code>&lt;cuda_runtime.h&gt;</code> to use CUDA functions that facilitate GPU computations.</p>
<h3 id="2-cuda-kernel-for-matrix-multiplication">2. CUDA Kernel for Matrix Multiplication<a hidden class="anchor" aria-hidden="true" href="#2-cuda-kernel-for-matrix-multiplication">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>__global__
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">matMulKernel</span>(<span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> A, <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> B, <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> C, <span style="color:#66d9ef">int</span> n) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> threadIdx.x <span style="color:#f92672">+</span> blockDim.x <span style="color:#f92672">*</span> blockIdx.x; <span style="color:#75715e">// Row index
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">int</span> j <span style="color:#f92672">=</span> threadIdx.y <span style="color:#f92672">+</span> blockDim.y <span style="color:#f92672">*</span> blockIdx.y; <span style="color:#75715e">// Column index
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">float</span> sum <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span>(i<span style="color:#f92672">&lt;</span>n <span style="color:#f92672">&amp;&amp;</span> j<span style="color:#f92672">&lt;</span>n) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> k <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; k <span style="color:#f92672">&lt;</span> n; k<span style="color:#f92672">++</span>)
</span></span><span style="display:flex;"><span>            sum <span style="color:#f92672">+=</span> A[i <span style="color:#f92672">*</span> n <span style="color:#f92672">+</span> k] <span style="color:#f92672">*</span> B[k <span style="color:#f92672">*</span> n <span style="color:#f92672">+</span> j];
</span></span><span style="display:flex;"><span>        C[i <span style="color:#f92672">*</span> n <span style="color:#f92672">+</span> j] <span style="color:#f92672">=</span> sum;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>This kernel function is executed on the GPU. Each thread in CUDA is responsible for computing one element of the result matrix <code>C</code>.</p>
<h3 id="breaking-down-the-cuda-kernel-with-an-example">Breaking Down the CUDA Kernel with an Example<a hidden class="anchor" aria-hidden="true" href="#breaking-down-the-cuda-kernel-with-an-example">#</a></h3>
<p>CUDA kernels execute in parallel, meaning that each thread operates on a specific element of the output matrix <code>C</code>. Let&rsquo;s break it down using an example.</p>
<h4 id="example-matrix-multiplication">Example Matrix Multiplication<a hidden class="anchor" aria-hidden="true" href="#example-matrix-multiplication">#</a></h4>
<p>Suppose we have two small matrices:</p>
<pre tabindex="0"><code>A = | 1 2 |    B = | 3 4 |
    | 3 4 |        | 5 6 |
</code></pre><p>The expected result <code>C = A × B</code> is:</p>
<pre tabindex="0"><code>C = | (1×3 + 2×5)  (1×4 + 2×6) |  =  | 13 16 |
    | (3×3 + 4×5)  (3×4 + 4×6) |     | 29 36 |
</code></pre><h3 id="how-cuda-threads-process-this-computation">How CUDA Threads Process This Computation<a hidden class="anchor" aria-hidden="true" href="#how-cuda-threads-process-this-computation">#</a></h3>
<p>Each thread computes a single element of <code>C</code>. Let&rsquo;s assume a 2×2 grid of threads.</p>
<ul>
<li><strong>Thread (0,0)</strong> computes <code>C[0][0]</code>:
<ul>
<li><code>i = 0</code> (row 0), <code>j = 0</code> (column 0)</li>
<li>Calculation: <code>1×3 + 2×5 = 13</code></li>
</ul>
</li>
<li><strong>Thread (0,1)</strong> computes <code>C[0][1]</code>:
<ul>
<li><code>i = 0</code> (row 0), <code>j = 1</code> (column 1)</li>
<li>Calculation: <code>1×4 + 2×6 = 16</code></li>
</ul>
</li>
<li><strong>Thread (1,0)</strong> computes <code>C[1][0]</code>:
<ul>
<li><code>i = 1</code> (row 1), <code>j = 0</code> (column 0)</li>
<li>Calculation: <code>3×3 + 4×5 = 29</code></li>
</ul>
</li>
<li><strong>Thread (1,1)</strong> computes <code>C[1][1]</code>:
<ul>
<li><code>i = 1</code> (row 1), <code>j = 1</code> (column 1)</li>
<li>Calculation: <code>3×4 + 4×6 = 36</code></li>
</ul>
</li>
</ul>
<p>Each thread retrieves the corresponding row from <code>A</code> and column from <code>B</code> and performs the dot product calculation independently. Since all threads execute in parallel, the computation completes much faster than sequential execution on a CPU.</p>
<h3 id="explanation-of-cuda-thread-indexing">Explanation of CUDA Thread Indexing<a hidden class="anchor" aria-hidden="true" href="#explanation-of-cuda-thread-indexing">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> threadIdx.x <span style="color:#f92672">+</span> blockDim.x <span style="color:#f92672">*</span> blockIdx.x; <span style="color:#75715e">// i represents row index
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span> j <span style="color:#f92672">=</span> threadIdx.y <span style="color:#f92672">+</span> blockDim.y <span style="color:#f92672">*</span> blockIdx.y; <span style="color:#75715e">// j represents column index
</span></span></span></code></pre></div><p>Each thread gets a unique <code>(i, j)</code> pair, which determines which element of <code>C</code> it calculates.</p>
<h4 id="understanding-index-computation">Understanding Index Computation<a hidden class="anchor" aria-hidden="true" href="#understanding-index-computation">#</a></h4>
<ul>
<li><code>A[i * n + k]</code> retrieves the element at row <code>i</code> and column <code>k</code> in <code>A</code>.</li>
<li><code>B[k * n + j]</code> retrieves the element at row <code>k</code> and column <code>j</code> in <code>B</code>.</li>
<li>The final computed <code>C[i * n + j]</code> is stored in the correct position in <code>C</code>.</li>
</ul>
<p>For example, for <code>i = 0</code>, <code>j = 1</code>:</p>
<ul>
<li>The kernel fetches <code>A[0 * 2 + k]</code> for <code>k = 0, 1</code>, which corresponds to row <code>0</code> in <code>A</code>.</li>
<li>It fetches <code>B[k * 2 + 1]</code>, which corresponds to column <code>1</code> in <code>B</code>.</li>
<li>The sum of the dot product is stored in <code>C[0 * 2 + 1]</code>, which is <code>C[0][1]</code>.</li>
</ul>
<p>This indexing system allows us to scale up the matrix multiplication to larger sizes by distributing computations across multiple threads and blocks.</p>
<h3 id="3-main-function-memory-allocation-and-execution">3. Main Function: Memory Allocation and Execution<a hidden class="anchor" aria-hidden="true" href="#3-main-function-memory-allocation-and-execution">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> n <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> A[n][n], B[n][n], C[n][n];
</span></span></code></pre></div><p>We define the size of matrices and allocate space in host (CPU) memory.</p>
<h4 id="initializing-matrices">Initializing Matrices<a hidden class="anchor" aria-hidden="true" href="#initializing-matrices">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span>n; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> j<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; j<span style="color:#f92672">&lt;</span>n; j<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>        A[i][j] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0f</span>;
</span></span><span style="display:flex;"><span>        B[i][j] <span style="color:#f92672">=</span> <span style="color:#ae81ff">2.0f</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We initialize matrix <code>A</code> with <code>1.0</code> and matrix <code>B</code> with <code>2.0</code>. This ensures predictable output, making debugging easier.</p>
<h4 id="copying-data-to-gpu">Copying Data to GPU<a hidden class="anchor" aria-hidden="true" href="#copying-data-to-gpu">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>cudaMemcpy(A_d, A, size, cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>cudaMemcpy(B_d, B, size, cudaMemcpyHostToDevice);
</span></span></code></pre></div><p>Using <code>cudaMemcpy</code>, we transfer the matrix data from CPU to GPU memory.</p>
<h3 id="4-launching-the-cuda-kernel">4. Launching the CUDA Kernel<a hidden class="anchor" aria-hidden="true" href="#4-launching-the-cuda-kernel">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>dim3 <span style="color:#a6e22e">blocksPerGrid</span>((<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>n<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">/</span>n, (<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>n<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">/</span>n);
</span></span><span style="display:flex;"><span>dim3 <span style="color:#a6e22e">threadsPerBlock</span>(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">16</span>);
</span></span><span style="display:flex;"><span>matMulKernel<span style="color:#f92672">&lt;&lt;&lt;</span>blocksPerGrid, threadsPerBlock<span style="color:#f92672">&gt;&gt;&gt;</span>(A_d, B_d, C_d, n);
</span></span></code></pre></div><h3 id="5-copying-results-back-to-cpu-and-printing">5. Copying Results Back to CPU and Printing<a hidden class="anchor" aria-hidden="true" href="#5-copying-results-back-to-cpu-and-printing">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>cudaMemcpy(C, C_d, size, cudaMemcpyDeviceToHost);
</span></span></code></pre></div><h3 id="6-freeing-memory">6. Freeing Memory<a hidden class="anchor" aria-hidden="true" href="#6-freeing-memory">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>cudaFree(A_d);
</span></span><span style="display:flex;"><span>cudaFree(B_d);
</span></span><span style="display:flex;"><span>cudaFree(C_d);
</span></span></code></pre></div><h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>This program demonstrates how to implement matrix multiplication using CUDA for parallel execution on the GPU. Understanding thread indexing, memory allocation, and kernel execution is key to writing efficient CUDA programs. By experimenting with different optimizations, we can further enhance performance and scalability.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Pratham Patel</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
